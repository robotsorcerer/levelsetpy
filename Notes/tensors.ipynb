{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb32a73-5159-41ae-8ae2-1c6c91f46ff8",
   "metadata": {},
   "source": [
    "### Tensor Decomposition Class\n",
    "\n",
    "Circa, November 2, 2021\n",
    "\n",
    "Author: Lekan Molux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd4607c-a23c-4c2c-8d40-06bb18049055",
   "metadata": {},
   "source": [
    "### [Usefuls]()\n",
    "\n",
    "+ [Accelerating Deep Neural Networks with Tensor Decompositions](https://jacobgil.github.io/deeplearning/tensor-decompositions-deep-learning)\n",
    "+ [Einstein Py](https://github.com/einsteinp./einsteinp.)\n",
    "+ [Projection on Tensor Product of Hilbert Space](https://math.stackexchange.com/questions/333537/projection-on-tensor-product-of-hilbert-space)\n",
    "+ [Tensor Decomposition for Signal Processing and Machine Learning](https://arxiv.org/pdf/1607.01668.pdf)\n",
    "+ [Tucker Compression Deep Learning](https://github.com/kittygo/tensor_decompostion/blob/master/tucker_compression.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5cd2cf-15c9-4bf3-9f2a-2a709d92086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as np.n",
    "import numpy as np.n",
    "import numpy.random as np.\n",
    "import sys, copy\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from Utilities import *\n",
    "from Tensors import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f02376-25ef-489e-9a70-28d259449551",
   "metadata": {},
   "outputs": [],
   "source": [
    "X12 = np.arange(1, 25).reshape(3, 4, 2, order='F')\n",
    "U = np.arange(1, 7).reshape(2, 3, order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f6714-3e8a-4398-8cd2-ca8221410f2a",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1486bd0a-b07a-4e57-80de-fe167e2ca97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mode_1_fiber: \n",
      " [[ 1  4  7 10 13 16 19 22]\n",
      " [ 2  5  8 11 14 17 20 23]\n",
      " [ 3  6  9 12 15 18 21 24]]\n",
      "\n",
      "mode_2_fiber: \n",
      " [[ 1  2  3 13 14 15]\n",
      " [ 4  5  6 16 17 18]\n",
      " [ 7  8  9 19 20 21]\n",
      " [10 11 12 22 23 24]]\n",
      "\n",
      "mode_3_fiber \n",
      " [[ 1  4  7 10  2  5  8 11  3  6  9 12]\n",
      " [13 16 19 22 14 17 20 23 15 18 21 24]]\n"
     ]
    }
   ],
   "source": [
    "#1-mode unfold\n",
    "\n",
    "mode_1_fiber = matricization(X12, mode='1')\n",
    "print('\\nmode_1_fiber: \\n', mode_1_fiber)\n",
    "\n",
    "#2-mode unfold\n",
    "\n",
    "mode_2_fiber = matricization(X12, mode='2')\n",
    "print('\\nmode_2_fiber: \\n', mode_2_fiber)\n",
    "\n",
    "#3-mode unfold\n",
    "mode_3_fiber = matricization(X12, mode='3')\n",
    "print('\\nmode_3_fiber \\n', mode_3_fiber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c119a53e-2115-4dd5-8709-15600c6efb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np..rand(5,3,4,2)\n",
    "A = np..rand(4,5); B =  np..rand(4,3); C =  np..rand(3,4); D =  np..rand(3,2);\n",
    "V = np.asarray([A, B, C, D], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb6562-5dbb-40aa-b863-f04463f760dc",
   "metadata": {},
   "source": [
    "### Test Tensor-Matrix Multiplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fc54eb-69d7-42a7-ac33-eeaa5955b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np..rand(5, 3, 4, 2)\n",
    "A = np..rand(4, 5); B = np..rand(4, 3); C = np..rand(3, 4); D = np..rand(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8242e8df-22ae-45a7-8a6e-96d164569aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 4, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tensor_matrix_mult(X, A, n=0, Transpose=False)\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c21d6bd-745c-448e-9001-f4f1392203b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 4, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as above\n",
    "T = tensor_matrix_mult(X, A.T, n=0, Transpose=True)\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a05365d-ab16-46a4-a317-74c1399e1657",
   "metadata": {},
   "source": [
    "#### Tensor by Block matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "936cc288-106f-42e9-8a93-44f1288b9ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 3, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tensor_matrix_mult(X, np.asarray([A, B, C, D], dtype=object), n=[0, 1, 2, 3])\n",
    "\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a249cf22-6f18-4070-a518-81e84d48379b",
   "metadata": {},
   "source": [
    "### Tucker Decomposition\n",
    "\n",
    "For a tensor $\\mathcal{X}$, the higher-order SVD for $\\mathcal{X}$ is generated by decomposing it into a core tensor multiplied by a matrix along each mode. For a 3D tensor, $\\mathcal{X} \\in \\mathbb{R}^{I \\times J \\times K}$, we have\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{X} = \\mathcal{G} \\times_1 A \\times_2 B \\times_3 C = \\sum_{p=1}^P \\sum_{q=1}^Q \\sum_{r=1}^R g_{pqr} \\, a_p \\circ b_q \\circ c_r = [\\mathcal{G}; A, B, C ]\n",
    "\\end{align}\n",
    "\n",
    "where $A \\in \\mathbb{R}^{I \\times P}, B \\in \\mathbb{R}^{J\\times Q}$, and $C=B \\in \\mathbb{R}^{K\\times R}$ are the factor matrices (typically orthogonal:=principal components in each mode).  $\\mathcal{G}  \\in \\mathbb{R}^{P \\times Q \\times R}$ is the core tensor, and its entries show the level of interaction between the different components.\n",
    "\n",
    "Elementwise, we write the Tucker decomposition as \n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{x}_{ijk} = \\sum_{p=1}^P \\sum_{q=1}^Q \\sum_{r=1}^R \\mathcal{g}_{pqr} \\, a_{ip} \\circ b_{jq} \\circ c_{kr}  \\forall \\, i = 1, \\cdots, I, j= 1, \\cdots J, k = 1, \\cdots, K.\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c46c2c-f86c-4095-b8e6-64529a4a53d4",
   "metadata": {},
   "source": [
    "In matricized form, we have per mode of each of the decomposition for a 3D tensor as\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{X}_{(1)} &\\approx  A \\, \\mathcal{G}_{(1)} \\, \\left(C \\otimes B\\right)^T \\\\\n",
    "    \\mathcal{X}_{(2)} &\\approx  B \\, \\mathcal{G}_{(2)} \\, \\left(C \\otimes A\\right)^T \\\\\n",
    "    \\mathcal{X}_{(3)} &\\approx  C \\, \\mathcal{G}_{(3)} \\, \\left(B \\otimes A\\right)^T \\\\\n",
    "\\end{align}\n",
    "\n",
    "where $\\otimes$ is the matrix Kronecker product defined for a matrix $F \\in \\mathbb{R}^{I\\times J}$ and $G \\in \\mathbb{R}^{K\\times L}$ as, \n",
    "\n",
    "\\begin{align}\n",
    "   F \\otimes G &=\\begin{bmatrix}\n",
    "                    f_{11} \\otimes G &  f_{12} \\otimes G &  f_{13} \\otimes G & \\cdots &  f_{1J} \\otimes G \\\\\n",
    "                    f_{21} \\otimes G &  f_{22} \\otimes G &  f_{23} \\otimes G & \\cdots &  f_{2J} \\otimes G \\\\\n",
    "            \\vdots &  \\vdots  &  \\vdots  & \\ddots &  \\vdots \\\\\n",
    "                    f_{I1} \\otimes G &  f_{I2} \\otimes G &  f_{I3} \\otimes G & \\cdots &  f_{IJ} \\otimes G \n",
    "                 \\end{bmatrix}  \\\\\n",
    "                 %\n",
    "              &=   \\begin{bmatrix}\n",
    "                       f_1 \\otimes g_1 & f_1 \\otimes g_2 & f_1 \\otimes g_3 & \\cdots & f_J \\otimes g_{L-1} & f_J \\otimes g_{L}\n",
    "                 \\end{bmatrix} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "30572b92-5839-4fa4-b587-39de368941de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np.n",
    "import numpy.random as np.\n",
    "from Tensors.leading_vecs import nvecs\n",
    "\n",
    "## adhoc functions/classes we'll need to get things rolling\n",
    "class TuckerTensor():\n",
    "    def __init__(self, core, U):\n",
    "        \"\"\"\n",
    "            Tucker Tensor Class:\n",
    "                Decomposes a high-order tensor into its core component and \n",
    "                a set of (usually) unitary matrices associated with every\n",
    "                mode of the tensor.\n",
    "                \n",
    "            Params\n",
    "            ------\n",
    "            core: The core tensor, whose entries shows the interaction among \n",
    "                  its components\n",
    "            U:    The factor matrices (typically orthogonal:=principal components\n",
    "                    in each mode)\n",
    "                    \n",
    "            Author: Lekan Molux\n",
    "            Date: November 2, 2021\n",
    "        \"\"\"\n",
    "        if isinstance(core, Tensor):\n",
    "            self.tensor = core\n",
    "        else:\n",
    "            self.tensor = Tensor(core, core.shape)\n",
    "        \n",
    "        self.U    = U\n",
    "        \n",
    "def tucker_als(X, R, **options):\n",
    "    \"\"\"\n",
    "        Performs Tucker's \"Method I\" for computing a rank \n",
    "        (R_1, R_2, \\cdots, R_N) Tucker decomposition, now known as HOSVD.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: Tensor to be decomposed\n",
    "        R: A single rank or best list of ranks to find in obtaining the Tucker SVD\n",
    "        options: {key:value} map of options to use in the alternating least square optimization\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        G: Core Tensor\n",
    "        [F_1, F_2, ...]: Factors of the Unitary Matrices for the modes of the tensor we are querying.\n",
    "        \n",
    "        Ref: Kolda and Baer Procedure HOSVD\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(X, Tensor):\n",
    "        X = X.data\n",
    "    \n",
    "    N = X.ndim\n",
    "    normX = np.linalg.norm(X)\n",
    "    \n",
    "    tol = options.get('tol', 1e-4)\n",
    "    max_iter = options.get('max_iter', 100)\n",
    "    dimorder = options.get('dimorder', list(range(N)))\n",
    "    init     = options.get('init', 'random')\n",
    "    verbose     = options.get('verbose', True)\n",
    "    \n",
    "    if np.isscalar(R):\n",
    "        R *= np.ones((N, 1), dtype=np.int64)\n",
    "    U = cell(N)\n",
    "    \n",
    "    assert max_iter > 0, \"maximum number of iteratons cannot be negative\"\n",
    "    \n",
    "    if strcmp(init,'random'):\n",
    "        Uinit = cell(N)\n",
    "        for n in dimorder[1:]:\n",
    "            Uinit[n] = np..rand(size(X,n),R[n])\n",
    "    elif strcmp(init,'nvecs') or strcmp(init,'eigs'):\n",
    "        # Compute an orthonormal basis for the dominant\n",
    "        # Rn-dimensional left singular subspace of\n",
    "        # X_(n) (1 <= n <= N).\n",
    "        Uinit = cell(N)\n",
    "        for n in dimorder[1:]:\n",
    "            info(f'Computing {R[n]} leading e-vectors for factor {n}.')\n",
    "            Uinit[n] = nvecs(X,n,R[n])\n",
    "    else:\n",
    "        raise ValueError('The selected initialization method is not supported.')\n",
    "        \n",
    "    U = Uinit\n",
    "    fit = 0\n",
    "\n",
    "    if verbose:\n",
    "        info('Tucker Alternating Least-Squares:')\n",
    "    \n",
    "    # Function Motherlode: Iterate until convergence\n",
    "    for iter in range(max_iter):\n",
    "        fitold = fit\n",
    "        \n",
    "        # iterate over all N modes of the tensor        \n",
    "        for n in dimorder:\n",
    "            Utilde = tensor_matrix_mult(X, U, -n, Transpose=True)\n",
    "            \n",
    "            'Max the norm of (U_tilde x_n W.T) w.r.t W and keep the'\n",
    "            'orthonormality of W.'            \n",
    "            U[n] = nvecs[Utilde, n, R[n]]\n",
    "        \n",
    "        # Assemble the approx        \n",
    "        core = tensor_matrix_mult(Utilde, U, n, Transpose=True)\n",
    "        \n",
    "        # Compute the fit\n",
    "        normresidual = np.sqrt(normX**2 - norm(core)**2)\n",
    "        fit = 1- (normresidual/normX)\n",
    "        fitchange = np.abs(fitold-fit)\n",
    "        \n",
    "        if iter%5==0:\n",
    "            info(f\"Iter: {iter:2d}, fit: {fit:.4f}, fitdelta: {fitchange:7.1f}\")\n",
    "    \n",
    "        # Did we converge yet?\n",
    "        if iter>1 and fitchange < fitchangetol:\n",
    "            break\n",
    "        \n",
    "    T = TuckerTensor(core, U)\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "6d13b8cc-1db3-46a7-8429-de46760d54cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-inp.t-371-672ed25c5aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtucker_als\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-inp.t-370-7e7eddd00223>\u001b[0m in \u001b[0;36mtucker_als\u001b[0;34m(X, R, **options)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# iterate over all N modes of the tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdimorder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mUtilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_matrix_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;34m'Max the norm of (U_tilde x_n W.T) w.r.t W and keep the'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML-Control-Rob/Reachability/LevelSetPy/Tensors/tensor_mat_mult.py\u001b[0m in \u001b[0;36mtensor_matrix_mult\u001b[0;34m(X, V, n, Transpose)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m'when we are multiplying with multiple arrays'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;34m'be careful that we do not give cupy object dtypes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp.u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'O'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "XX = tucker_als(X, [3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "3115d34f-24e6-4b45-ad33-310811df1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ \t\t= \"Lekan Molu\"\n",
    "__copyright__ \t= \"2021, Decomposing Level Sets of PDEs\"\n",
    "__credits__  \t= \"Sylvia Herbert, Ian Abraham\"\n",
    "__license__ \t= \"Lekan License\"\n",
    "__maintainer__ \t= \"Lekan Molu\"\n",
    "__email__ \t\t= \"patlekno@icloud.com\"\n",
    "__status__ \t\t= \"Fix Tensor Mode Swap in Memory Layout.\"\n",
    "\n",
    "import numpy as np.n",
    "from Utilities import *\n",
    "\n",
    "class TenMat():\n",
    "    def __init__(self, T, **options):\n",
    "        \"\"\"\n",
    "            This class provides the boilerpate for matricizing a Tensor.\n",
    "            \n",
    "            # TODO: Why does Numpy flip 0-Mode with 1-Mode?\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            T:       A Tensor < see class_tensor.py />.\n",
    "            options: A bundle class. If it is a dictionary, it is converted to a bundle.\n",
    "                     It contains the following fields:\n",
    "                rdims: A numpy/cupy (dtype=intp) index array which specifies the modes of T to \n",
    "                       which we map the rows of a matrix, and the remaining \n",
    "                       dimensions (in ascending order) map to the columns.\n",
    "                cdims:  A numpy/cupy (dtype=intp) index array which specifies the modes of T to \n",
    "                       which we map the   columns of a matrix, and the \n",
    "                       remaining dimensions (in ascending order) map \n",
    "                       to the rows.\n",
    "                cyclic: String which specifies the dimension in rdim which\n",
    "                        maps to the rows of the matrix, and the remaining \n",
    "                        dimensions span the columns in an order specified \n",
    "                        by the string argument \"cyclic\" as follows:\n",
    "\n",
    "                      'fc' - Forward cyclic.  Order the remaining dimensions in the\n",
    "                           columns by [rdim+1:T.ndim, 1:rdim-1].  This is the\n",
    "                           ordering defined by Kiers.\n",
    "\n",
    "                       'bc' - Backward cyclic.  Order the remaining dimensions in the\n",
    "                           columns by [rdim-1:-1:1, T.ndim:-1:rdim+1].  \n",
    "                           This is the ordering defined by De Lathauwer, De Moor, and Vandewalle.\n",
    "\n",
    "            Calling Signatures\n",
    "            ------------------\n",
    "            TenMat(T, options.rdims): Create a matrix representation of a tensor\n",
    "                T.  The dimensions (or modes) specified in rdims map to the rows\n",
    "                of the matrix, and the remaining dimensions (in ascending order)\n",
    "                map to the columns.\n",
    "\n",
    "            TenMat(T, cdims, Transpose=True): Similar to rdims, but for column\n",
    "                dimensions are specified, and the remaining dimensions (in\n",
    "                ascending order) map to the rows.\n",
    "\n",
    "            TenMat(T, rdims, cdims): Create a matrix representation of\n",
    "               tensor T.  The dimensions specified in RDIMS map to the rows of\n",
    "               the matrix, and the dimensions specified in CDIMS map to the\n",
    "               columns, in the order given.\n",
    "\n",
    "            TenMat(T, rdim, cyclic): Create the same matrix representation as\n",
    "               above, except only one dimension in rdim maps to the rows of the\n",
    "               matrix, and the remaining dimensions span the columns in an order\n",
    "               specified by the string argument STR as follows:\n",
    "\n",
    "              'fc' - Forward cyclic.  Order the remaining dimensions in the\n",
    "                           columns by [rdim+1:T.ndim, 1:rdim-1].  This is the\n",
    "                           ordering defined by Kiers.\n",
    "\n",
    "               'bc' - Backward cyclic.  Order the remaining dimensions in the\n",
    "                           columns by [rdim-1:-1:1, T.ndim:-1:rdim+1].  This is the\n",
    "                           ordering defined by De Lathauwer, De Moor, and Vandewalle.\n",
    "\n",
    "            TenMat(T, options=Bundle({rdims, cdims, tsize})): Create a tenmat from a matrix\n",
    "                   T along with the mappings of the row (rdims) and column indices\n",
    "                   (cdims) and the size of the original tensor (T.shape).\n",
    "\n",
    "            Author: Lekan Molux, November 3, 2021\n",
    "        \"\"\"\n",
    "        \n",
    "        assert isinstance(T, Tensor), 'T must be a tensor class.'\n",
    "        assert T.data.ndim !=2, \"Inp.t Tensor must be 2D.\"\n",
    "        assert isinstance(T, Tensor), \"T must be of class tensor type.\"\n",
    "        \n",
    "        if not isbundle(options) and isinstance(options, dict):\n",
    "            options = Bundle(options)\n",
    "        assert isbundle(options), \"options must be of Bundle class.\"\n",
    "        \n",
    "        self.tsize = np.asarray(options.__dict__.get(\"tsize\", T.shape), dtype=np.intp)\n",
    "        self.rindices = options.__dict__.get(\"rdims\", None)\n",
    "        self.cindices = options.__dict__.get(\"cdims\", None)\n",
    "        self.data = T.data        \n",
    "        self.T= T\n",
    "        \n",
    "        tsize = np.asarray(options.__dict__.get(\"tsize\", T.shape), dtype=np.intp)\n",
    "        rdims = options.__dict__.get(\"rdims\", None)\n",
    "        cdims = options.__dict__.get(\"cdims\", None)\n",
    "        data  = T.data\n",
    "        \n",
    "        n = numel(tsize)\n",
    "        \n",
    "        if np.any(rdims) and np.any(cdims):\n",
    "            dims_joined = np.concatenate((rdims, cdims))\n",
    "        elif np.any(rdims) and not np.any(cdims):\n",
    "            dims_joined = rdims\n",
    "        elif not np.any(rdims) and np.any(cdims):\n",
    "            dims_joined = cdims\n",
    "                        \n",
    "        if not np.allclose(range(n), np.sort(dims_joined)):\n",
    "            raise ValueError('Incorrect dimension specifications.')\n",
    "        elif (np.prod(self.tsize[rdims]) != size(self.data, 0)):\n",
    "            raise ValueError('T.shape[0] does not match size specified by rdims and shape.')\n",
    "        elif (np.prod(self.tsize[cdims]) != size(self.data, 1)):\n",
    "            raise ValueError('T.shape[1] does not match size specified by cdims and shape.')\n",
    "            \n",
    "        tsize = T.shape\n",
    "        n     = T.ndim\n",
    "        \n",
    "        tmp = np.zeros((n), dtype=bool)\n",
    "        tmp.fill(True)\n",
    "        if np.any(rdims):\n",
    "            tmp[np.ix_(*rdims)] = False\n",
    "            cdims = np.nonzero(tmp)\n",
    "        \n",
    "        if isfield(options, 'cyclic') and options.cyclic=='T':\n",
    "            cdims = copy.copy(options.rdims)\n",
    "            tmp = np.zeros((n), dtype=bool)\n",
    "            tmp.fill(True)\n",
    "            tmp[np.ix_(*cdims)] = False            \n",
    "            rdims = np.nonzero(tmp)\n",
    "            \n",
    "        elif isfield(options, 'cyclic') and options.cyclic=='fc':\n",
    "            rdims = options.rdims\n",
    "            \n",
    "            if numel(rdims)!=1:\n",
    "                raise ValueError('Only one row dimension if third argument is ''fc''.')\n",
    "            cdims = np.concatenate((np.arange(rdims, n, dtype=np.intp), \\\n",
    "                                    np.arange(rdims-1, dtype=np.intp)), dtype=np.intp)\n",
    "            \n",
    "        elif isfield(options, 'cyclic') and options.cyclic=='bc':\n",
    "            rdims = options.rdims\n",
    "            \n",
    "            if numel(rdims)!=1:\n",
    "                raise ValueError('Only one row dimension if third argument is ''bc''.')\n",
    "                \n",
    "            cdims = np.concatenate((np.arange(rdims, -1, 1, dtype=np.intp),\\\n",
    "                                    np.arange(n-1, -1, rdims+1, dtype=np.intp)), dtype=np.intp)\n",
    "        else:\n",
    "            raise ValueError('Unrecognized option.')\n",
    "        \n",
    "        rdims = options.rdims\n",
    "        cdims = options.cdims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "84364054-f4e4-4e8a-9b93-c2f78e71d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np.n",
    "from Utilities import *\n",
    "\n",
    "class TenMat():\n",
    "    def __init__(self, T, **options):\n",
    "    #def __init__(self, T, rdims=None, cdims=None, cyclic=None):\n",
    "        \"\"\"\n",
    "        This class provides the boilerpate for matricizing a Tensor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        T:       A Tensor < see class_tensor.py />.\n",
    "        options: A bundle class. If it is a dictionary, it is converted to a bundle.\n",
    "                 It contains the following fields:\n",
    "            rdims: A numpy/cupy (dtype=np.np.intp) index array which specifies the modes of T to \n",
    "                   which we map the rows of a matrix, and the remaining \n",
    "                   dimensions (in ascending order) map to the columns.\n",
    "            cdims:  A numpy/cupy (dtype=np.np.intp) index array which specifies the modes of T to \n",
    "                   which we map the   columns of a matrix, and the \n",
    "                   remaining dimensions (in ascending order) map \n",
    "                   to the rows.\n",
    "            cyclic: String which specifies the dimension in rdim which\n",
    "                    maps to the rows of the matrix, and the remaining \n",
    "                    dimensions span the columns in an order specified \n",
    "                    by the string argument \"cyclic\" as follows:\n",
    "\n",
    "                  'fc' - Forward cyclic.  Order the remaining dimensions in the\n",
    "                       columns by [rdim+1:T.ndim, 1:rdim-1].  This is the\n",
    "                       ordering defined by Kiers.\n",
    "\n",
    "                   'bc' - Backward cyclic.  Order the remaining dimensions in the\n",
    "                       columns by [rdim-1:-1:1, T.ndim:-1:rdim+1].  \n",
    "                       This is the ordering defined by De Lathauwer, De Moor, and Vandewalle.\n",
    "\n",
    "        Calling Signatures\n",
    "        ------------------\n",
    "        TenMat(T, options.rdims): Create a matrix representation of a tensor\n",
    "            T.  The dimensions (or modes) specified in rdims map to the rows\n",
    "            of the matrix, and the remaining dimensions (in ascending order)\n",
    "            map to the columns.\n",
    "\n",
    "        TenMat(T, cdims, Transpose=True): Similar to rdims, but for column\n",
    "            dimensions are specified, and the remaining dimensions (in\n",
    "            ascending order) map to the rows.\n",
    "\n",
    "        TenMat(T, rdims, cdims): Create a matrix representation of\n",
    "           tensor T.  The dimensions specified in RDIMS map to the rows of\n",
    "           the matrix, and the dimensions specified in CDIMS map to the\n",
    "           columns, in the order given.\n",
    "\n",
    "        TenMat(T, rdim, cyclic): Create the same matrix representation as\n",
    "           above, except only one dimension in rdim maps to the rows of the\n",
    "           matrix, and the remaining dimensions span the columns in an order\n",
    "           specified by the string argument STR as follows:\n",
    "           'T' - Transpose.\n",
    "\n",
    "          'fc' - Forward cyclic.  Order the remaining dimensions in the\n",
    "                       columns by [rdim+1:T.ndim, 1:rdim-1].  This is the\n",
    "                       ordering defined by Kiers.\n",
    "\n",
    "           'bc' - Backward cyclic.  Order the remaining dimensions in the\n",
    "                       columns by [rdim-1:-1:1, T.ndim:-1:rdim+1].  This is the\n",
    "                       ordering defined by De Lathauwer, De Moor, and Vandewalle.\n",
    "\n",
    "        TenMat(T, options=Bundle({rdims, cdims, tsize})): Create a tenmat from a matrix\n",
    "               T along with the mappings of the row (rdims) and column indices\n",
    "               (cdims) and the size of the original tensor (T.shape).\n",
    "               \n",
    "        Example: \n",
    "            X  = np.arange(1, 28).reshape(3,3,3)\n",
    "            # print('X ', X)\n",
    "            options = dict(rdims=np.array([2], dtype=np.intp))\n",
    "            X_1 = TenMat(X, **options)\n",
    "\n",
    "        Author: Lekan Molux, November 3, 2021\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(T, Tensor):\n",
    "            T = Tensor(T, T.shape)\n",
    "            \n",
    "            \n",
    "        if not isbundle(options) and isinstance(options, dict):\n",
    "            options = Bundle(options)\n",
    "        assert isbundle(options), \"options must be of Bundle class.\"\n",
    "\n",
    "        self.tsize = np.asarray(options.__dict__.get(\"tsize\", T.shape))\n",
    "        self.rindices = options.__dict__.get(\"rdims\", None)\n",
    "        self.cindices = options.__dict__.get(\"cdims\", None)\n",
    "        self.data = T.data    \n",
    "\n",
    "        if self.rindices is None and self.cindices is None:\n",
    "            return\n",
    "\n",
    "        tsize = np.asarray(options.__dict__.get(\"tsize\", T.shape))\n",
    "        rdims = options.__dict__.get(\"rdims\", None)\n",
    "        cdims = options.__dict__.get(\"cdims\", None)\n",
    "        data  = T.data\n",
    "\n",
    "        n = T.data.ndim\n",
    "            \n",
    "        if len(options)==1:\n",
    "        #if isfield(options, 'rdims') and not isfield(options, 'cdims'):\n",
    "            tmp = np.zeros((n), dtype=bool)\n",
    "            tmp.fill(True)\n",
    "            tmp[rdims] = False\n",
    "            cdims = np.nonzero(tmp)[0]\n",
    "        #elif isfield(options, 'cyclic'):\n",
    "        elif len(options)>=2: #isfield(options, 'cyclic'):\n",
    "            if options.cyclic=='T':\n",
    "                cdims = options.rdims \n",
    "                tmp = np.zeros((n,1), dtype=bool)\n",
    "                tmp.fill(True)\n",
    "                tmp[cdims] = False\n",
    "                rdims = np.nonzero(tmp)[0]\n",
    "            elif options.cyclic=='fc':\n",
    "                rdims = options.rdims\n",
    "                if numel(rdims)!=1:\n",
    "                    raise ValueError(f'Only one row dimension if options.cyclic is ''fc''.')\n",
    "                cdims = np.concatenate((np.arange(rdims, n, dtype=np.intp), \\\n",
    "                                        np.arange(rdims-1, dtype=np.intp)), dtype=np.intp)\n",
    "            elif options.cyclic=='bc':\n",
    "                rdims = options.rdims\n",
    "\n",
    "                if numel(rdims)!=1:\n",
    "                    raise ValueError('Only one row dimension if third argument is ''bc''.')\n",
    "\n",
    "                cdims = np.concatenate((np.arange(rdims-1, dtype=np.intp)[::-1],\\\n",
    "                                        np.arange(rdims, n, dtype=np.intp)[::-1]), dtype=np.intp)\n",
    "            else:\n",
    "                raise ValueError('Unrecognized option.')\n",
    "\n",
    "        else:\n",
    "            rdims = options.rdims\n",
    "            cdims = options.cdims\n",
    "\n",
    "        # Error check\n",
    "        if not np.array_equal(np.arange(n), np.sort( np.concatenate((rdims, cdims)))):\n",
    "            raise ValueError('Incorrect specification of dimensions')\n",
    "\n",
    "        # Permute T so that the dimensions specified by RDIMS come first\n",
    "        T_Rot = np.transpose(T.data, axes=np.concatenate([rdims, cdims]))\n",
    "        rprods = np.prod(tsize[rdims])\n",
    "        np.ods = np.prod(tsize[cdims]) \n",
    "        \n",
    "        self.data     = T_Rot.reshape(rprods, np.ods)\n",
    "        self.rindices = rdims\n",
    "        self.cindices = cdims\n",
    "        self.tsize    = tsize \n",
    "        self.T = Tensor(self.data, shape=self.data.shape)\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.T\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "98b57a2f-07ec-4e21-b4ea-1e188165312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XC:  False\n"
     ]
    }
   ],
   "source": [
    "X  = np.arange(1, 28).reshape(3,3,3)\n",
    "X1 = np.arange(1, 10).reshape(3,3, 1)\n",
    "X2 = np.arange(10, 19).reshape(3,3, 1)\n",
    "X3 = np.arange(19, 28).reshape(3,3, 1)\n",
    "XC = np.array_equal(X, np.concatenate((X1, X2, X3), axis =0))\n",
    "print('XC: ', XC)\n",
    "# print('X ', X)\n",
    "options = dict(rdims=np.array([0], dtype=np.intp))\n",
    "X_1 = TenMat(X, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "c8271efc-1eac-4002-bc30-78ea6aa8e7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
       "        [19, 20, 21, 22, 23, 24, 25, 26, 27]]),\n",
       " array([0]),\n",
       " array([1, 2]),\n",
       " array([3, 3, 3]))"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.data, X_1.rindices, X_1.cindices, X_1.tsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "78f3450f-75b1-4977-9600-558b7ea39ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XX  [[[ 1 10 19]\n",
      "  [ 2 11 20]\n",
      "  [ 3 12 21]]\n",
      "\n",
      " [[ 4 13 22]\n",
      "  [ 5 14 23]\n",
      "  [ 6 15 24]]\n",
      "\n",
      " [[ 7 16 25]\n",
      "  [ 8 17 26]\n",
      "  [ 9 18 27]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1, 10, 19,  2, 11, 20,  3, 12, 21],\n",
       "        [ 4, 13, 22,  5, 14, 23,  6, 15, 24],\n",
       "        [ 7, 16, 25,  8, 17, 26,  9, 18, 27]]),\n",
       " [0],\n",
       " array([1, 2]))"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = np.concatenate((X1, X2, X3), 2)\n",
    "print('XX ', XX)\n",
    "XX1 = TenMat(XX, rdims=[0])\n",
    "XX1.data, XX1.rindices, XX1.cindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "0f5b1bf1-51a6-405e-af05-41aa04fa0146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1],\n",
       "        [ 2],\n",
       "        [ 3]],\n",
       "\n",
       "       [[ 4],\n",
       "        [ 5],\n",
       "        [ 6]],\n",
       "\n",
       "       [[ 7],\n",
       "        [ 8],\n",
       "        [ 9]],\n",
       "\n",
       "       [[10],\n",
       "        [11],\n",
       "        [12]],\n",
       "\n",
       "       [[13],\n",
       "        [14],\n",
       "        [15]],\n",
       "\n",
       "       [[16],\n",
       "        [17],\n",
       "        [18]],\n",
       "\n",
       "       [[19],\n",
       "        [20],\n",
       "        [21]],\n",
       "\n",
       "       [[22],\n",
       "        [23],\n",
       "        [24]],\n",
       "\n",
       "       [[25],\n",
       "        [26],\n",
       "        [27]]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559043f2-a6f8-4a17-ba18-60f49d45f8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
