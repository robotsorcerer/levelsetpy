{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1f018b-8abb-4633-ba5b-d6552c09e9c5",
   "metadata": {},
   "source": [
    "### Implements algorithm 1 in the parti-game [paper](https://link.springer.com/content/pdf/10.1007/BF00993591.pdf)\n",
    "\n",
    "Learn a controller from a start region to a goal region on a continuous space; Four increasingly effective algorithms to partition discrete state spaces. Algorithm 1 and 2 are non-learning; 3 and 4 learn, hence explore, the world while planning a route to the goal. Here, I implement algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90777b02-daa8-4888-a211-241eb6961a13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2c827018ee83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "\n",
    "import utils\n",
    "import pickle\n",
    "\n",
    "\n",
    "def get_mgrid(sidelen, dim=2):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.'''\n",
    "    if isinstance(sidelen, int):\n",
    "        sidelen = dim * (sidelen,)\n",
    "\n",
    "    if dim == 2:\n",
    "        pixel_coords = np.stack(np.mgrid[:sidelen[0], :sidelen[1]], axis=-1)[None, ...].astype(np.float32)\n",
    "        pixel_coords[0, :, :, 0] = pixel_coords[0, :, :, 0] / (sidelen[0] - 1)\n",
    "        pixel_coords[0, :, :, 1] = pixel_coords[0, :, :, 1] / (sidelen[1] - 1)\n",
    "    elif dim == 3:\n",
    "        pixel_coords = np.stack(np.mgrid[:sidelen[0], :sidelen[1], :sidelen[2]], axis=-1)[None, ...].astype(np.float32)\n",
    "        pixel_coords[..., 0] = pixel_coords[..., 0] / max(sidelen[0] - 1, 1)\n",
    "        pixel_coords[..., 1] = pixel_coords[..., 1] / (sidelen[1] - 1)\n",
    "        pixel_coords[..., 2] = pixel_coords[..., 2] / (sidelen[2] - 1)\n",
    "    else:\n",
    "        raise NotImplementedError('Not implemented for dim=%d' % dim)\n",
    "\n",
    "    pixel_coords -= 0.5\n",
    "    pixel_coords *= 2.\n",
    "    pixel_coords = torch.Tensor(pixel_coords).view(-1, dim)\n",
    "    return pixel_coords\n",
    "\n",
    "\n",
    "def to_uint8(x):\n",
    "    return (255. * x).astype(np.uint8)\n",
    "\n",
    "\n",
    "def to_numpy(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def gaussian(x, mu=[0, 0], sigma=1e-4, d=2):\n",
    "    x = x.numpy()\n",
    "    if isinstance(mu, torch.Tensor):\n",
    "        mu = mu.numpy()\n",
    "\n",
    "    q = -0.5 * ((x - mu) ** 2).sum(1)\n",
    "    return torch.from_numpy(1 / np.sqrt(sigma ** d * (2 * np.pi) ** d) * np.exp(q / sigma)).float()\n",
    "\n",
    "\n",
    "class ReachabilityMultiVehicleCollisionSourceNE(Dataset):\n",
    "    def __init__(self, numpoints,\n",
    "     collisionR=0.25, velocity=0.6, omega_max=1.1,\n",
    "     pretrain=False, tMin=0.0, tMax=0.5, counter_start=0, counter_end=100e3, \n",
    "     numEvaders=1, pretrain_iters=2000, angle_alpha=1.0, time_alpha=1.0,\n",
    "     num_src_samples=1000):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        self.pretrain = pretrain\n",
    "        self.numpoints = numpoints\n",
    "        \n",
    "        self.velocity = velocity\n",
    "        self.omega_max = omega_max\n",
    "        self.collisionR = collisionR\n",
    "\n",
    "        self.alpha_angle = angle_alpha * math.pi\n",
    "        self.alpha_time = time_alpha\n",
    "\n",
    "        self.numEvaders = numEvaders\n",
    "        self.num_states_per_vehicle = 3\n",
    "        self.num_states = self.num_states_per_vehicle * (numEvaders + 1)\n",
    "        self.num_pos_states = 2 * (numEvaders + 1)\n",
    "        # The state sequence will be as follows\n",
    "        # [x-y position of vehicle 1, x-y position of vehicle 2, ...., x-y position of vehicle N, heading of vehicle 1, heading of vehicle 2, ...., heading of vehicle N]\n",
    "\n",
    "        self.tMin = tMin\n",
    "        self.tMax = tMax\n",
    "\n",
    "        self.N_src_samples = num_src_samples\n",
    "\n",
    "        self.pretrain_counter = 0\n",
    "        self.counter = counter_start\n",
    "        self.pretrain_iters = pretrain_iters\n",
    "        self.full_count = counter_end \n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_time = 0.  # time to apply  initial conditions\n",
    "\n",
    "        # uniformly sample domain and include coordinates where source is non-zero \n",
    "        coords = torch.zeros(self.numpoints, self.num_states).uniform_(-1, 1)\n",
    "\n",
    "        if self.pretrain:\n",
    "            # only sample in time around the initial condition\n",
    "            # time = torch.zeros(self.numpoints, 1).uniform_(start_time - 0.001, start_time + 0.001)\n",
    "            time = torch.ones(self.numpoints, 1) * start_time\n",
    "            coords = torch.cat((time, coords), dim=1)\n",
    "        else:\n",
    "            # slowly grow time values from start time\n",
    "            # this currently assumes start_time = tMin and max time value is tMax\n",
    "            time = self.tMin + torch.zeros(self.numpoints, 1).uniform_(0, (self.tMax-self.tMin) * (self.counter / self.full_count))\n",
    "        \n",
    "            coords = torch.cat((time, coords), dim=1)\n",
    "\n",
    "            # make sure we always have training samples at the initial time\n",
    "            coords[-self.N_src_samples:, 0] = start_time\n",
    "\n",
    "        # set up the initial value function\n",
    "        # Collision cost between the pursuer and the evaders\n",
    "        boundary_values = torch.norm(coords[:, 1:3] - coords[:, 3:5], dim=1, keepdim=True) - self.collisionR\n",
    "        for i in range(1, self.numEvaders):\n",
    "            boundary_values_current = torch.norm(coords[:, 1:3] - coords[:, 2*(i+1)+1:2*(i+1)+3], dim=1, keepdim=True) - self.collisionR\n",
    "            boundary_values = torch.min(boundary_values, boundary_values_current)\n",
    "        # Collision cost between the evaders themselves\n",
    "        for i in range(self.numEvaders):\n",
    "            for j in range(i+1, self.numEvaders):\n",
    "                evader1_coords_index = 1 + (i+1)*2\n",
    "                evader2_coords_index = 1 + (j+1)*2\n",
    "                boundary_values_current = torch.norm(coords[:, evader1_coords_index:evader1_coords_index+2] - coords[:, evader2_coords_index:evader2_coords_index+2], dim=1, keepdim=True) - self.collisionR\n",
    "                boundary_values = torch.min(boundary_values, boundary_values_current)\n",
    "\n",
    "        # normalize the value function\n",
    "        norm_to = 0.02\n",
    "        mean = 0.25\n",
    "        var = 0.5\n",
    "        boundary_values = (boundary_values - mean)*norm_to/var\n",
    "        \n",
    "        if self.pretrain:\n",
    "            dirichlet_mask = torch.ones(coords.shape[0], 1) > 0\n",
    "        else:\n",
    "            # only enforce initial conditions around start_time\n",
    "            dirichlet_mask = (coords[:, 0, None] == start_time)\n",
    "\n",
    "        if self.pretrain:\n",
    "            self.pretrain_counter += 1\n",
    "        elif self.counter < self.full_count:\n",
    "            self.counter += 1\n",
    "\n",
    "        if self.pretrain and self.pretrain_counter == self.pretrain_iters:\n",
    "            self.pretrain = False\n",
    "\n",
    "        return {'coords': coords}, {'source_boundary_values': boundary_values, 'dirichlet_mask': dirichlet_mask}\n",
    "\n",
    "\n",
    "class ReachabilityAir3DSource(Dataset):\n",
    "    def __init__(self, numpoints, \n",
    "        collisionR=0.25, velocity=0.6, omega_max=1.1, \n",
    "        pretrain=False, tMin=0.0, tMax=0.5, counter_start=0, counter_end=100e3, \n",
    "        pretrain_iters=2000, angle_alpha=1.0, num_src_samples=1000, seed=0):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        self.pretrain = pretrain\n",
    "        self.numpoints = numpoints\n",
    "        \n",
    "        self.velocity = velocity\n",
    "        self.omega_max = omega_max\n",
    "        self.collisionR = collisionR\n",
    "\n",
    "        self.alpha_angle = angle_alpha * math.pi\n",
    "\n",
    "        self.num_states = 3\n",
    "\n",
    "        self.tMax = tMax\n",
    "        self.tMin = tMin\n",
    "\n",
    "        self.N_src_samples = num_src_samples\n",
    "\n",
    "        self.pretrain_counter = 0\n",
    "        self.counter = counter_start\n",
    "        self.pretrain_iters = pretrain_iters\n",
    "        self.full_count = counter_end \n",
    "\n",
    "        # Set the seed\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_time = 0.  # time to apply  initial conditions\n",
    "\n",
    "        # uniformly sample domain and include coordinates where source is non-zero \n",
    "        coords = torch.zeros(self.numpoints, self.num_states).uniform_(-1, 1)\n",
    "\n",
    "        if self.pretrain:\n",
    "            # only sample in time around the initial condition\n",
    "            time = torch.ones(self.numpoints, 1) * start_time\n",
    "            coords = torch.cat((time, coords), dim=1)\n",
    "        else:\n",
    "            # slowly grow time values from start time\n",
    "            # this currently assumes start_time = 0 and max time value is tMax\n",
    "            time = self.tMin + torch.zeros(self.numpoints, 1).uniform_(0, (self.tMax-self.tMin) * (self.counter / self.full_count))\n",
    "            coords = torch.cat((time, coords), dim=1)\n",
    "\n",
    "            # make sure we always have training samples at the initial time\n",
    "            coords[-self.N_src_samples:, 0] = start_time\n",
    "\n",
    "        # set up the initial value function\n",
    "        boundary_values = torch.norm(coords[:, 1:3], dim=1, keepdim=True) - self.collisionR\n",
    "\n",
    "        # normalize the value function\n",
    "        norm_to = 0.02\n",
    "        mean = 0.25\n",
    "        var = 0.5\n",
    "\n",
    "        boundary_values = (boundary_values - mean)*norm_to/var\n",
    "        \n",
    "        if self.pretrain:\n",
    "            dirichlet_mask = torch.ones(coords.shape[0], 1) > 0\n",
    "        else:\n",
    "            # only enforce initial conditions around start_time\n",
    "            dirichlet_mask = (coords[:, 0, None] == start_time)\n",
    "\n",
    "        if self.pretrain:\n",
    "            self.pretrain_counter += 1\n",
    "        elif self.counter < self.full_count:\n",
    "            self.counter += 1\n",
    "\n",
    "        if self.pretrain and self.pretrain_counter == self.pretrain_iters:\n",
    "            self.pretrain = False\n",
    "\n",
    "        return {'coords': coords}, {'source_boundary_values': boundary_values, 'dirichlet_mask': dirichlet_mask}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a0143-3286-4eb7-8597-13ee282b169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODOs\n",
    "# to be written \n",
    "addGhostPeriodic\n",
    "addGhostExtrapolate\n",
    "processGrid\n",
    "getNumericalFuncs\n",
    "odeCFLset\n",
    "termRestrictUpdate\n",
    "termLaxFriedrichs\n",
    "termTraceHessian\n",
    "hessianSecond\n",
    "termSum\n",
    "truncateGrid\n",
    "hjipde_solve  # stopped at line 1011"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
